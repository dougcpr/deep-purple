import asyncio
import numpy
import os
import sys
import time

try:
    # we might not have opencv available on the system
    import cv2
except ImportError as e:
    cv2 = None

from av import VideoFrame
from aiortc import VideoStreamTrack
from fractions import Fraction

if sys.version_info < (3, 6):
    raise Exception("This module must be run in Python3.6+")


class FreedomVideoStream(VideoStreamTrack):
    def __init__(self, logger, settings):
        super().__init__()
        self.logger = logger
        self.current_image = None
        self.current_frame = None
        self.last_received_image = None
        self.last_received_frame_time = None
        self.last_frame_time = None  # received or assisted

        self.settings = settings

        self.time_base = Fraction(1, 90000)

        self.start_time = time.time()
        self.image_number = -1
        self.last_image_number = -1

        # flag for enabling/disabling entire assistance functionality
        self.assistance_enabled = True
        # initial time after which the assistance jump in with new frames if no frames received
        self.assistance_jump_in_interval = 1.0
        # delay between assisted frames
        self.assistance_update_delay = 0.2
        # starting assistance loop
        asyncio.ensure_future(self.assist_stream())

    @property
    def max_width(self):
        return self.settings.get('width', self.settings.get('max_width', 640))

    @property
    def max_height(self):
        return self.settings.get('height', self.settings.get('max_height', 480))

    @property
    def max_fps(self):
        return self.settings.get('fps', self.settings.get('max_fps', 10))

    async def stop_assistance(self, delay):
        await asyncio.sleep(delay)
        self.assistance_enabled = False

    def set_assistance_params(self, delay, fps):
        self.assistance_jump_in_interval = delay
        self.assistance_update_delay = 1/min(fps, self.max_fps)

    async def assist_stream(self):
        """
        This method is starting a loop which assures that there will be frames updating
        This will be done by re-publish the last image.
        If no real image was published yet, it will try to read and use the image from 'frame0.jpg'
        or on empty black image if the jpg image is not readable (missing opencv module)

        This will keep the video stream alive.
        :return:
        """
        if cv2 is not None:
            image0 = cv2.imread(
                os.path.join(
                    os.path.dirname(os.path.abspath(__file__)),
                    'frame0.jpg'))
        else:
            # we could not read the default frame0 image, using black image
            self.logger.warning('We could not import cv2, '
                                'please install opencv for {}, for better performance.'.format(sys.executable))
            self.logger.debug('Using a black image as frame0 could not be read')
            # using 1/4 of the max resolution and grayscale to lower bandwidth usage
            image0 = numpy.ones((int(self.max_width/4), int(self.max_height/4)), numpy.uint8)

        while self.assistance_enabled:
            now = time.time()
            if self.last_frame_time is None or \
                    ((self.last_received_frame_time is None or
                      (now - self.last_received_frame_time > self.assistance_jump_in_interval))
                     and now - self.last_frame_time > self.assistance_update_delay):
                if self.current_image is not None:
                    img = self.current_image
                    if self.last_received_image is not None:
                        img = numpy.copy(self.last_received_image)
                        red = (58, 33, 237)
                        black = (0, 0, 0)
                        if img.ndim == 2:
                            red, black = 255, 0

                        # next commented text is for testing the text positioning at various resolutions
                        # import random
                        # x = 0.1 + random.random()
                        # y = 0.1 + random.random()
                        # h, w = img.shape[0:2]
                        # img = cv2.resize(img, dsize=(int(x*w), int(y*h)), interpolation=cv2.INTER_CUBIC)
                        # h, w = img.shape[0:2]
                        # print('{}x{}'.format(h, w))

                        if cv2 is not None:
                            # if cv2 is available will will add text on image to indicate how old is it
                            h, w = img.shape[0:2]
                            font_scale = max(w, h) / 1100
                            font_thickness = int(font_scale * 3.5)
                            text = '{:.1f}s old frame'.format(now - self.last_received_frame_time)
                            text_size = cv2.getTextSize(
                                text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)[0]
                            rm = int(min(text_size)*0.2)  # rectangle margins
                            orig_w = int(0.5*w-text_size[0]/2)
                            orig_h = int(0.3*h+text_size[1]/2)
                            cv2.rectangle(
                                img=img,
                                pt1=(orig_w-rm, orig_h+rm),
                                pt2=(orig_w+rm+text_size[0], orig_h-rm-text_size[1]),
                                color=red,
                                thickness=cv2.FILLED
                            )
                            cv2.putText(
                                img=img,
                                text=text,
                                org=(orig_w, orig_h),
                                fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                                fontScale=font_scale,
                                color=black,
                                thickness=font_thickness
                            )
                        # complicated to do more than the red rectangle without opencv
                        self.add_borders(img, red)
                    self.set_image(img, assisted=True)
                    # print('Assistance worked for {}s'.format(time.time() - now))
                else:
                    self.set_image(image0, assisted=True)
            await asyncio.sleep(0.250)

    @staticmethod
    def add_borders(image, color):
        """
        This method will add borders to an given image
        Note that it is highly inefficient, installing opencv would allow us running faster implementations
        :param image: image to add borders to
        :param color: BGR color
        :return: None
        """
        h, w = image.shape[0:2]
        border_size = int(max(h, w) * 3 / 100)  # border is 3% of the image size
        if cv2 is not None:
            cv2.rectangle(
                img=image,
                pt1=(0, 0),
                pt2=(w, h),
                color=color,
                thickness=2*border_size
            )
        else:
            image[0:border_size, :] = color
            image[-border_size:, :] = color
            image[:, 0:border_size] = color
            image[:, -border_size:] = color

    def set_image(self, img, assisted=False):
        self.last_frame_time = time.time()

        self.current_image = img
        # Adding smaller size

        if not assisted:
            self.last_received_frame_time = self.last_frame_time
            self.last_received_image = img
        # detecting the image format for the frame
        # https://github.com/mikeboers/PyAV/blob/develop/av/video/frame.pyx
        if img.ndim == 3:
            img_format = 'bgr24'
        elif img.ndim == 2:
            img_format = 'gray'

        self.current_frame = VideoFrame.from_ndarray(self.current_image, format=img_format)

        # shrinking image if needed
        h, w = img.shape[0:2]
        ratio = min([self.max_height / h, self.max_width / w])
        # this reformating is done by aiortc if we don't do it here
        # (final frame must be in yuv420p format)
        # so, using opencv to do it is redundant and leads to reformating twice
        self.current_frame = self.current_frame.reformat(
            format="yuv420p",
            width=int(min((ratio * w), self.max_width)),
            height=int(min((ratio * h), self.max_height)),
            # interpolation='FAST_BILINEAR'
        )

        self.image_number = self.image_number + 1

    async def recv(self):
        if self.current_frame is None:
            return None

        # This blocks sending another frame until we get a new actual image
        # to send
        while self.image_number == self.last_image_number:
            await asyncio.sleep(0.01)

        self.current_frame.time_base = self.time_base
        self.current_frame.pts = int((time.time() - self.start_time) / self.time_base)

        self.last_image_number = self.image_number

        return self.current_frame
